{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Module2_FT_vF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1RZo5yGGpS-"
      },
      "source": [
        "# Information\n",
        "Title: Artificial Intelligence in Insurance Claims Management - Computer vision for car damage recognition \n",
        "\n",
        "Author: Roman Kastl\n",
        "\n",
        "# Training & Fine-tuning EfficientNetB0 - Module 2 - vF\n",
        "- Use transfer learning to classify images of damaged vs. non-damaged car\n",
        "- EfficientNetB0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMfSMS3SeMe1"
      },
      "source": [
        "# Build, train, and save models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSuOkpgNeRB3"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woA3KOiP-qX5"
      },
      "source": [
        "!git clone https://github.com/djehuty94/MasterThesis_CarDamageRecognition\r\n",
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_JQIn_DGpTA"
      },
      "source": [
        "### Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NrW7DPpGpTB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pathlib\n",
        "import PIL\n",
        "import random\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "#Only if we use colab\n",
        "#from google.colab import files\n",
        "from tensorflow.python.client import device_lib\n",
        "import torch\n",
        "\n",
        "#Import tensorboard plugins\n",
        "import tensorboard as tb\n",
        "from scipy import stats\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from packaging import version\n",
        "import seaborn as sns\n",
        "\n",
        "#Library for model scheme\n",
        "import pydot\n",
        "import graphviz\n",
        "import pydotplus\n",
        "\n",
        "#Require tensorflow >= 2.3\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "import tensorflow_addons as tfa\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz8Abty6_LlL"
      },
      "source": [
        "# Name variables for output file\r\n",
        "model_version = \"vF\"\r\n",
        "step_name =\"Training and Fine-tuning\"\r\n",
        "module_name = \"Module2\"\r\n",
        "save_path = \"\"\r\n",
        "\r\n",
        "# Dummy variable for \r\n",
        "save_shape_plot = True\r\n",
        "save_training_plot = True \r\n",
        "save_model = True\r\n",
        "save_history = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv3wQR39VWdZ"
      },
      "source": [
        "### Set seed value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpWNI5WbVWde"
      },
      "source": [
        "# Set the Random Seed\n",
        "seed_value= 123\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq9C7SqjVWd3"
      },
      "source": [
        "### Check that model will run on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82BcpY4vmd3L"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJeTFLdhgGAz"
      },
      "source": [
        "torch.cuda.is_available()\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD0IT60pVWd7"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "\n",
        "# Create some tensors\n",
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "c = tf.matmul(a, b)\n",
        "\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47B8Ui9iGpTF"
      },
      "source": [
        "## Part 1 - Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-2-Xy1-eepu"
      },
      "source": [
        "### - Recover data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u56JofdYUMBq"
      },
      "source": [
        "From Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3IJQQMxRhAQ"
      },
      "source": [
        "data_dir = pathlib.Path(\"MasterThesis_CarDamageRecognition/Data/Dataset_v2_cat_location\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4n4XDWiGpTK"
      },
      "source": [
        "### - Count the number of existing image and display"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anCkSq9wGpTL"
      },
      "source": [
        "#count the total number of image\n",
        "image_count = len(list(data_dir.glob('*/*/')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCczMR8xGpTS"
      },
      "source": [
        "### Pre-process the images and prepare the training, validation and test set\n",
        "This part split the dataset in a training (80%) and test dataset (20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3UMBEY4VWg-"
      },
      "source": [
        "#Preprocess the picture and prepare the set keras\n",
        "batch_size = 32\n",
        "img_size = (224,224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMetNgpqGpTT"
      },
      "source": [
        "#Generate a training and validation dataset, in the next cell, a test dataset is generated from the validation dataset\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  label_mode='categorical',\n",
        "  image_size= img_size ,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size)\n",
        "  \n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  label_mode='categorical',\n",
        "  image_size=img_size,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A8rtFS4VWhd"
      },
      "source": [
        "#Skip the test set and only use a training and validation set for Module 2 and 3, due to the limited quantity of training data\n",
        "\n",
        "#As not test dataset is available, we will extract a few pictures from the validation dataset\n",
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "test_ds = val_ds.take(val_batches // 5)\n",
        "val_ds = val_ds.skip(val_batches // 5)\n",
        "\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ls9H5ZGpTY"
      },
      "source": [
        "target_dict={k: v for v, k in enumerate(np.unique(train_ds.class_names))}\n",
        "class_names = np.array(train_ds.class_names)\n",
        "num_classes = len(class_names)\n",
        "print(class_names)\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9x1RT1DGpTX"
      },
      "source": [
        "### Display a few images of each class\n",
        "\n",
        "As we can observed, 0 refers to the damage class and 1 to regular car pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DW9DVe9f2Pb"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "for images, labels in train_ds.take(1):\r\n",
        "    for i in range(9):\r\n",
        "        ax = plt.subplot(3, 3, i + 1)\r\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n",
        "        plt.title(class_names[np.argmax(labels[i])])\r\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHXx3Xj8f5iD"
      },
      "source": [
        "#Print dataset format\r\n",
        "# Here we use a batch of 32, the image dimensions are 224x224 and RGB (3)\r\n",
        "for image_batch, labels_batch in train_ds:\r\n",
        "  print(image_batch.shape)\r\n",
        "  print(labels_batch.shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RLnqriuGpTj"
      },
      "source": [
        "### Configure dataset for performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igTGoHn6GpTj"
      },
      "source": [
        "#Optimize the datasets for performances\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "588Cv5VZGpTn"
      },
      "source": [
        "## Part 2 - Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSvzlN2IVWja"
      },
      "source": [
        "### Build Callbacks and Training method\n",
        "\n",
        "Callback: \n",
        "\n",
        "- EarlyStopping: Stop training the model if loss on validation set has not improved over 3 iterations\n",
        "- ModelCheckpoint: Save the best model based on the validation accuracy\n",
        "- WIP - TensorBoard: Generate the data for a tensorboard \n",
        "\n",
        "\n",
        "Model:\n",
        "- EfficientNet-B0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMsOuv2Rfq_k"
      },
      "source": [
        "def train_model(model_to_train,callbacks, epochs):\r\n",
        "    model_to_train\r\n",
        "    history_model_to_train = model_to_train.fit(\r\n",
        "        train_ds,\r\n",
        "        validation_data=val_ds,\r\n",
        "        epochs=epochs,\r\n",
        "        callbacks=callbacks\r\n",
        "    )\r\n",
        "    return(model_to_train,history_model_to_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9QsCgn3eyfn"
      },
      "source": [
        "### COMPILE THE MODEL\n",
        "if num_classes == 2:\n",
        "    loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    METRICS = [\n",
        "             'accuracy',\n",
        "             keras.metrics.Precision(name='precision'),\n",
        "             keras.metrics.Recall(name='recall'),             \n",
        "             tfa.metrics.F1Score(name='f1-score',average='macro',num_classes=num_classes,threshold=0.5),\n",
        "             ]\n",
        "else:\n",
        "    loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    METRICS = [\n",
        "             'accuracy',\n",
        "             keras.metrics.Precision(name='precision'),\n",
        "             keras.metrics.Recall(name='recall'),             \n",
        "             tfa.metrics.F1Score(name='f1-score',average='macro',num_classes=num_classes,threshold=0.5),\n",
        "             tfa.metrics.F1Score(name='f1-score_perClass',num_classes=num_classes,threshold=0.5)             \n",
        "             ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klN72XrXe5Yu"
      },
      "source": [
        "def build_callback(model_name, patience, verbose):\r\n",
        "    callbacks_list = [\r\n",
        "     keras.callbacks.EarlyStopping(\r\n",
        "         monitor=\"val_loss\",\r\n",
        "         patience=patience,\r\n",
        "         verbose=verbose,\r\n",
        "         mode=\"auto\",\r\n",
        "         restore_best_weights=True,\r\n",
        "     ),\r\n",
        "      keras.callbacks.TensorBoard(\r\n",
        "          log_dir=\"logs/fit/\"+model_name,\r\n",
        "          histogram_freq=1,\r\n",
        "          embeddings_freq=1,\r\n",
        "          )]\r\n",
        "    if save_model == True:\r\n",
        "      {\r\n",
        "        callbacks_list.append(\r\n",
        "         keras.callbacks.ModelCheckpoint(\r\n",
        "         filepath=save_path+\"\"+model_name+\".h5\",\r\n",
        "         monitor=\"val_loss\",\r\n",
        "         save_best_only=True,\r\n",
        "     ))\r\n",
        "      }\r\n",
        "\r\n",
        "    return(callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW3908Lme1VE"
      },
      "source": [
        "\n",
        "### Data augmentation\n",
        "\n",
        "In this code data augmentation is achieved through layers which are added to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_je37nxGpTo"
      },
      "source": [
        "#Create layer for image augmentation\n",
        "#It will help to prevent overfitting\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.15),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOs27D6eGpTt"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzlV6MoVGpTw"
      },
      "source": [
        "### Build and Compile EfficientNetB0\n",
        "- Initialize\n",
        "- Pass Data augmentation\n",
        "- Preprocess the input specially for EfficientNetB0\n",
        "- Add top set of layer (GlobalMaxPooling2D + BatchNorm + Dropout 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMQERqidjvg"
      },
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "#Make the EfficientNetB0 model\n",
        "def make_model_EfficientNetB0(input_shape, num_classes, model_arch_name):\n",
        "\n",
        "    ### BUILD THE MODEL\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    preprocess_input_EfficientNetB0 = keras.applications.efficientnet.preprocess_input\n",
        "    x = preprocess_input_EfficientNetB0(x)\n",
        "    \n",
        "    #We do not want the base to be trainable, otherwise we would lose all the advantagres of using pre-trained model\n",
        "    #conv_base_EfficientNetB0  = EfficientNetB0(weights='imagenet',include_top=False,input_tensor=x, drop_connect_rate=0.2)      \n",
        "    conv_base_EfficientNetB0  = EfficientNetB0(weights='imagenet',include_top=False,input_tensor=x)      \n",
        "    conv_base_EfficientNetB0.trainable = False\n",
        "    conv_base_EfficientNetB0.summary()\n",
        "\n",
        "    #Rebuild top, starting with a GlobalMaxPooling in order to convert the feature maps in vectors\n",
        "    x = keras.layers.GlobalMaxPooling2D(name=\"top_GlobalMaxPooling2D\")(conv_base_EfficientNetB0.output)\n",
        "    x = layers.BatchNormalization(name=\"topBatchNorm\")(x)\n",
        "\n",
        "    dropout_rate = 0.5\n",
        "    x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)    \n",
        "\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "    outputs = layers.Dense(units, activation=activation, name=\"pred\")(x)\n",
        "    model = keras.Model(inputs, outputs, name=\"EfficientNetB0\")\n",
        "    \n",
        "    #a learning rate of 1e-2 reduced the valuation f1\n",
        "    opt = Adam(lr=1e-3)\n",
        "    \n",
        "    model.compile(optimizer=opt, loss=loss_func, metrics=METRICS)\n",
        "    \n",
        "    #model.summary()\n",
        "    if (save_shape_plot == True):\n",
        "      keras.utils.plot_model(model,show_shapes=True,to_file=save_path+model_arch_name+\"_plot.png\")\n",
        "    return(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnwul2CCVWj-"
      },
      "source": [
        "### Build chart to evaluate the model training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTZIYV0HxPdX"
      },
      "source": [
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "def plot_metrics(history, key):\n",
        "  metrics =  ['accuracy','loss','f1-score']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n",
        "    fig = plt.gcf()\n",
        "    if(save_training_plot == True):\n",
        "      fig.savefig(save_path+key+\"_training_plot.png\", dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V79ulu5YRewP"
      },
      "source": [
        "### JSON export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRiyvMKHRiDj"
      },
      "source": [
        "def json_export(name, data):\n",
        "  df = pd.DataFrame.from_dict(data)\n",
        "  csv_path = save_path+module_name+\"_\"+model_version+\"_history_df_\"+name+\".csv\"\n",
        "  df.to_csv(csv_path, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oASjJtfoHyJ7"
      },
      "source": [
        "## Part 3 - Compile, train and assess EfficientNet-B0\n",
        "Can only run one of the below, must restart the session in between the compilation of two model. The goal is to uniform the tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daLj-T8eZ9df"
      },
      "source": [
        "###Compile and summary of EfficientNet-B0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klrO_Hjwdj2D"
      },
      "source": [
        "model_EfficientNetB0 = make_model_EfficientNetB0(img_size+(3,),num_classes, \"EfficientNetB0\")\n",
        "model_EfficientNetB0.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPPNrzujaIhv"
      },
      "source": [
        "### Train EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4upOPftKdj2b"
      },
      "source": [
        "#Set to 30 because we do not want early stopping for cause of Visual rendering, but we still use early stopping in order to restore the best weights\n",
        "epochs = 30\n",
        "patience = epochs\n",
        "verbose = 1\n",
        "\n",
        "callbacks_EfficientNetB0 = build_callback(\"EfficientNetB0\", patience, verbose)\n",
        "model_EfficientNetB0, history_model_EfficientNetB0 = train_model(model_EfficientNetB0, callbacks_EfficientNetB0, epochs)\n",
        "# Save it under the form of a json file\n",
        "if save_history == True:\n",
        "  json_export(\"EfficientNetB0\", history_model_EfficientNetB0.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ7GiemjaPW-"
      },
      "source": [
        "### Chart the model EfficientNet-B0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhgcPVaZa4zn"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "plot_metrics(history_model_EfficientNetB0.history,\"EfficientNetB0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JllvbNFuZOl0"
      },
      "source": [
        "## Part 4 - Fine-tune the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Axrh5Kdz4uA"
      },
      "source": [
        "### Determine layers to unfreeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D6uy-tVi6Cf"
      },
      "source": [
        " #model_EfficientNetB0.summary()\r\n",
        "for layer in model_EfficientNetB0.layers[-9:]:\r\n",
        "  print(layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-4HuzfHz7Dw"
      },
      "source": [
        "### Build unfreeze_model method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTRYY_IYa6T2"
      },
      "source": [
        "def unfreeze_model(model):\r\n",
        "    # We unfreeze the top 20 layers, corresponding to the Block 7 of the EfficientNet-B0 model, use 21 if the Dense 128 layer is added on top\r\n",
        "    for layer in model.layers[-9:]:\r\n",
        "        if not isinstance(layer, layers.BatchNormalization):\r\n",
        "            layer.trainable = True\r\n",
        "\r\n",
        "    #Lower learning rate to 1e-4 for fine-tuning\r\n",
        "    opt = Adam(lr=1e-4)\r\n",
        "    \r\n",
        "    model.compile(optimizer=opt, loss=loss_func, metrics=METRICS)\r\n",
        "\r\n",
        "unfreeze_model(model_EfficientNetB0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR-4rdxMd45v"
      },
      "source": [
        "model_EfficientNetB0.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ3RFBA3z-mt"
      },
      "source": [
        "### Train the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITKNf5eFeajg"
      },
      "source": [
        "#Set to 30 because we do not want early stopping for cause of Visual rendering, but we still use early stopping in order to restore the best weights\r\n",
        "epochs = 30\r\n",
        "patience = epochs\r\n",
        "verbose = 1\r\n",
        "\r\n",
        "callbacks_EfficientNetB0 = build_callback(\"EfficientNetB0_ft\", patience, verbose)\r\n",
        "model_EfficientNetB0, history_model_EfficientNetB0 = train_model(model_EfficientNetB0, callbacks_EfficientNetB0, epochs)\r\n",
        "# Save it under the form of a json file\r\n",
        "if save_history == True:\r\n",
        "  json_export(\"EfficientNetB0_ft\", history_model_EfficientNetB0.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBqyyfas0HLw"
      },
      "source": [
        "### Chart the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rizlolJggwj3"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\r\n",
        "plot_metrics(history_model_EfficientNetB0.history,\"EfficientNetB0_ft\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqXKqYJCQEyi"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cc8lFp3GKI6"
      },
      "source": [
        "#Update to Tensorboard\n",
        "!tensorboard dev upload --logdir ./logs \\\n",
        "  --name \"Training & Fine-tuning - Module 2 - vF\" \\\n",
        "  --description \"EfficientNet-B0 - Max Pooling, Batch Normalization, Dropout = 0.5\" \\\n",
        "  --one_shot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HQoqYRufnG1"
      },
      "source": [
        "## Access Tensorboard and build chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSGxH65gfqMe"
      },
      "source": [
        "https://www.tensorflow.org/tensorboard/dataframe_api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M00hkqtafu1V"
      },
      "source": [
        "experiment_id = \"ID RETURNED ABOVE\"\r\n",
        "\r\n",
        "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\r\n",
        "dfw = experiment.get_scalars(pivot=True) \r\n",
        "dfw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idD40JM8ghdM"
      },
      "source": [
        "csv_path = save_path+module_name+\"_\"+model_version+\"_experiment.csv\"\r\n",
        "dfw.to_csv(csv_path, index=False)\r\n",
        "dfw_roundtrip = pd.read_csv(csv_path)\r\n",
        "pd.testing.assert_frame_equal(dfw_roundtrip, dfw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntEVisS9yBr4"
      },
      "source": [
        "dfw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDvRj250prxu"
      },
      "source": [
        "# Filter the DataFrame to only validation data, which is what the subsequent\r\n",
        "# analyses and visualization will be focused on.\r\n",
        "dfw_validation = dfw[dfw.run.str.endswith(\"/validation\")]\r\n",
        "# Get the optimizer value for each row of the validation DataFrame.\r\n",
        "optimizer_validation = dfw_validation.run.apply(lambda run: run.split(\",\")[0])\r\n",
        "\r\n",
        "plt.figure(figsize=(16, 6))\r\n",
        "plt.subplot(1, 2, 1)\r\n",
        "sns.lineplot(data=dfw_validation, x=\"step\", y=\"epoch_f1-score\", \r\n",
        "             hue=optimizer_validation).set_title(\"f1-score\")\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "sns.lineplot(data=dfw_validation, x=\"step\", y=\"epoch_loss\",\r\n",
        "             hue=optimizer_validation).set_title(\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tltRqXRKY3_c"
      },
      "source": [
        "dfw.groupby('run')['epoch_f1-score'].nlargest(1,)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTlliRi8cbTG"
      },
      "source": [
        "### EfficientNet-B0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Q-C1N6cgxk"
      },
      "source": [
        "dfw_EfficientNetB0 = dfw[dfw.run.str.startswith(\"fit/EfficientNetB0/\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJkH5WuvcaoV"
      },
      "source": [
        "# Get the optimizer value for each row of the validation DataFrame\n",
        "optimizer_validation = dfw_EfficientNetB0.run.apply(lambda run: run.split(\",\")[0])\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.lineplot(data=dfw_EfficientNetB0, x=\"step\", y=\"epoch_f1-score\", \n",
        "             hue=optimizer_validation).set_title(\"f1-score\")\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.lineplot(data=dfw_EfficientNetB0, x=\"step\", y=\"epoch_accuracy\",\n",
        "             hue=optimizer_validation).set_title(\"accuracy\")\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.lineplot(data=dfw_EfficientNetB0, x=\"step\", y=\"epoch_loss\",\n",
        "             hue=optimizer_validation).set_title(\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk2krHQ9vOeH"
      },
      "source": [
        "dfw_EfficientNetB0_ft = dfw[dfw.run.str.startswith(\"fit/EfficientNetB0_ft\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UgTnLTFvPs8"
      },
      "source": [
        "# Get the optimizer value for each row of the validation DataFrame.\n",
        "optimizer_validation = dfw_EfficientNetB0_ft.run.apply(lambda run: run.split(\",\")[0])\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.lineplot(data=dfw_EfficientNetB0_ft, x=\"step\", y=\"epoch_f1-score\", \n",
        "             hue=optimizer_validation).set_title(\"f1-score\")\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.lineplot(data=dfw_EfficientNetB0_ft, x=\"step\", y=\"epoch_accuracy\",\n",
        "             hue=optimizer_validation).set_title(\"accuracy\")\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.lineplot(data=dfw_EfficientNetB0_ft, x=\"step\", y=\"epoch_loss\",\n",
        "             hue=optimizer_validation).set_title(\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAc5rvOVWkY"
      },
      "source": [
        "# Load and evaluate models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkm02p53geTD"
      },
      "source": [
        "## Part 1 - Load the model and evaluate its accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnJAcAL-gpe7"
      },
      "source": [
        "model = model_EfficientNetB0\n",
        "model_name = \"EfficientNetB0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ney64gZDJjKA"
      },
      "source": [
        "def model_accuracy():\n",
        "  loss, acc, precision, recall, f1, f1_perclass = model.evaluate(test_ds)\n",
        "  print('Restored model '+model_name+', accuracy: {:5.2f}%'.format(100*acc))\n",
        "  print(model.predict(test_ds).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoXVJ3OAVWka"
      },
      "source": [
        "model_accuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7vuuMOEVWk7"
      },
      "source": [
        "## Part 2 - Proceed to multiple predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPkvgB-Kjl4"
      },
      "source": [
        "def model_predict():\n",
        "  #Retrieve a batch of images from the test set\n",
        "  image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
        "  predictions = model.predict_on_batch(image_batch)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "    x = class_names[np.argmax(label_batch[i])]\n",
        "    y = class_names[np.argmax(predictions[i])]\n",
        "    plt.title(\"Actual:\"+ x +\"\\nPredicted:\"+ y +\"\")\n",
        "    plt.axis(\"off\")\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAgw-htgVWk8"
      },
      "source": [
        "predictions = model_predict()\n",
        "#Retrieve a batch of images from the test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkvdPzRyM_yP"
      },
      "source": [
        "#Check\n",
        "np.sum(predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYHAov_HdL27"
      },
      "source": [
        "## Part 3 - Single Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o93SXb9hxKo"
      },
      "source": [
        "## Provide the prediction for a single image\n",
        "\n",
        "#Choose image path\n",
        "img_path = \"IMG_PATH\"\n",
        "\n",
        "img = keras.preprocessing.image.load_img(\n",
        "      img_path, target_size=img_size\n",
        "  )\n",
        "\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "print(f\"The algorithm says this image is:\\n {prediction[0,0]:.2%} {class_names[0]}\\n and {prediction[0,1]:.2%} {class_names[1]}\\n and {prediction[0,2]:.2%} {class_names[2]}\\n\")\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}