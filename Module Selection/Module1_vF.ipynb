{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Module1_vF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1RZo5yGGpS-"
      },
      "source": [
        "# Information\n",
        "Title: Artificial Intelligence in Insurance Claims Management - Computer vision for car damage recognition \n",
        "\n",
        "Author: Roman Kastl\n",
        "\n",
        "# Model Selection\n",
        "## Module 1 - vF\n",
        "- Use transfer learning to classify images of damaged vs. non-damaged car\n",
        "- VGG16\n",
        "- Xception\n",
        "- Resnet50V2\n",
        "- EfficientNetB0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMfSMS3SeMe1"
      },
      "source": [
        "# Build, train, and save models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2aOuWGjw-rT"
      },
      "source": [
        "!git clone https://github.com/djehuty94/MasterThesis_CarDamageRecognition\r\n",
        "!pip install -U tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSuOkpgNeRB3"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_JQIn_DGpTA"
      },
      "source": [
        "### Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NrW7DPpGpTB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pathlib\n",
        "import PIL\n",
        "import random\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "#Only if we use colab\n",
        "#from google.colab import files\n",
        "from tensorflow.python.client import device_lib\n",
        "import torch\n",
        "\n",
        "#Import tensorboard plugins\n",
        "import tensorboard as tb\n",
        "from scipy import stats\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from packaging import version\n",
        "import seaborn as sns\n",
        "\n",
        "#Library for model scheme\n",
        "import pydot\n",
        "import graphviz\n",
        "import pydotplus\n",
        "\n",
        "#Require tensorflow >= 2.3\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "import tensorflow_addons as tfa\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9clxJTBjV4L"
      },
      "source": [
        "# Name variables for output file\n",
        "model_version = \"vF\"\n",
        "step_name =\"Model Selection\"\n",
        "module_name = \"Module1\"\n",
        "save_path = \"\"\n",
        "\n",
        "# Dummy variable for \n",
        "save_shape_plot = True\n",
        "save_training_plot = True \n",
        "save_model = True\n",
        "save_history = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv3wQR39VWdZ"
      },
      "source": [
        "### Set seed value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpWNI5WbVWde"
      },
      "source": [
        "# Set the Random Seed\n",
        "seed_value= 123\n",
        "\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq9C7SqjVWd3"
      },
      "source": [
        "### *Colab*: Check that model will run on GPU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebmI-kvkUyX7"
      },
      "source": [
        "gpu_info = !nvidia-smi\r\n",
        "gpu_info = '\\n'.join(gpu_info)\r\n",
        "if gpu_info.find('failed') >= 0:\r\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n",
        "  print('and then re-execute this cell.')\r\n",
        "else:\r\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJeTFLdhgGAz"
      },
      "source": [
        "torch.cuda.is_available()\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47B8Ui9iGpTF"
      },
      "source": [
        "## Part 1 - Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-2-Xy1-eepu"
      },
      "source": [
        "### - Recover data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyQEZnktGpTG"
      },
      "source": [
        "data_dir = pathlib.Path(\"MasterThesis_CarDamageRecognition/Data/Dataset_v1_bin_damage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anCkSq9wGpTL"
      },
      "source": [
        "#count the total number of image\n",
        "image_count = len(list(data_dir.glob('*/*/')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCczMR8xGpTS"
      },
      "source": [
        "### Pre-process the images and prepare the training, validation and test set\n",
        "This part split the dataset in a training (80%) and test dataset (20%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3UMBEY4VWg-"
      },
      "source": [
        "#Define the image and batch size\n",
        "batch_size = 32\n",
        "img_size = (224,224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMetNgpqGpTT"
      },
      "source": [
        "# Generate a training and validation dataset, in the next cell, a test dataset is generated from the validation dataset\n",
        "# I use a categorical labelling in order for the code to be easily used with multiple classes \n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  label_mode='categorical',\n",
        "  image_size= img_size ,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size)\n",
        "  \n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  label_mode='categorical',\n",
        "  image_size=img_size,\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A8rtFS4VWhd"
      },
      "source": [
        "#A test dataset is built from the training dataset\n",
        "val_batches = tf.data.experimental.cardinality(val_ds)\n",
        "test_ds = val_ds.take(val_batches // 5)\n",
        "val_ds = val_ds.skip(val_batches // 5)\n",
        "\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ls9H5ZGpTY"
      },
      "source": [
        "#The class names and number of classes in separate variables\n",
        "target_dict={k: v for v, k in enumerate(np.unique(train_ds.class_names))}\n",
        "class_names = np.array(train_ds.class_names)\n",
        "num_classes = len(class_names)\n",
        "print(class_names)\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9x1RT1DGpTX"
      },
      "source": [
        "### Display a few images of each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-394Sy4eKV2V"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[np.argmax(labels[i])])\n",
        "        plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCLSjPCLGpTg"
      },
      "source": [
        "#Print the format of the dataset\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break\n",
        "#The batch size is 32, the image dimensions are 224x224 and three dimensionals (32, 224, 224, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RLnqriuGpTj"
      },
      "source": [
        "### Configure dataset for performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igTGoHn6GpTj"
      },
      "source": [
        "#Optimize the datasets for performances\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "588Cv5VZGpTn"
      },
      "source": [
        "## Part 2 - Build the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW3908Lme1VE"
      },
      "source": [
        "\n",
        "### Data augmentation\n",
        "\n",
        "In this code data augmentation is achieved through layers which are added to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_je37nxGpTo"
      },
      "source": [
        "#Create a layer for data augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.15),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOs27D6eGpTt"
      },
      "source": [
        "#Display an image of an image with the augmentation filter applied\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzlV6MoVGpTw"
      },
      "source": [
        "### Build the Models\n",
        "- Initialize\n",
        "- Pass Data augmentation\n",
        "- Rescale /255, /127.5 and 0;1 or -1;1 depending on the model transferred\n",
        "- Add a GlobalMaxPooling2D, BatchNormalization, and Dropout on top of the transferred model\n",
        "- Output layer - Sigmoid function (Binary output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnYJJoUjHyJi"
      },
      "source": [
        "#### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBWNCvufwWLG"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "#Make the VGG model\n",
        "def make_model_VGG16(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    preprocess_input_VGG16 = keras.applications.vgg16.preprocess_input\n",
        "    x = preprocess_input_VGG16(x)\n",
        "    \n",
        "    #We do not want the base to be trainable, otherwise we would lose all the advantagres of using pre-trained model\n",
        "    conv_base_VGG16 = VGG16(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "    conv_base_VGG16.trainable = False\n",
        "    conv_base_VGG16.summary()\n",
        "\n",
        "    x = conv_base_VGG16(x, training=False)\n",
        "\n",
        "    #Rebuild top\n",
        "    #Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "    x = keras.layers.GlobalMaxPooling2D(name=\"top_GlobalMaxPooling2D\")(x)\n",
        "    x = layers.BatchNormalization(name=\"topBatchNorm\")(x)\n",
        "\n",
        "    dropout_rate = 0.5\n",
        "    x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)    \n",
        "\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "    outputs = layers.Dense(units, activation=activation, name=\"pred\")(x)\n",
        " \n",
        "    return keras.Model(inputs, outputs, name=\"VGG16_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a1WL_TKHyJl"
      },
      "source": [
        "#### Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLOYpjY7HyJm"
      },
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "#Make the Xception model\n",
        "def make_model_Xception(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    preprocess_input_Xception = keras.applications.xception.preprocess_input\n",
        "    x = preprocess_input_Xception(x)\n",
        "    \n",
        "    #We do not want the base to be trainable, otherwise we would lose all the advantagres of using pre-trained model\n",
        "    conv_base_Xception = Xception(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "    conv_base_Xception.trainable = False\n",
        "    conv_base_Xception.summary()\n",
        "\n",
        "    x = conv_base_Xception(x, training=False)\n",
        "    \n",
        "    #Rebuild top\n",
        "    #Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "    x = keras.layers.GlobalMaxPooling2D(name=\"top_GlobalMaxPooling2D\")(x)\n",
        "    x = layers.BatchNormalization(name=\"topBatchNorm\")(x)\n",
        "\n",
        "    dropout_rate = 0.5\n",
        "    x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)    \n",
        "\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "    outputs = layers.Dense(units, activation=activation, name=\"pred\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs, name=\"Xception\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMz2eL8mHyJo"
      },
      "source": [
        "#### Resnet50V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLU78aANdjvB"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50V2\n",
        "\n",
        "#Make the Resnet50V2 model\n",
        "def make_model_Resnet50V2(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    preprocess_input_Resnet50V2 = keras.applications.resnet_v2.preprocess_input\n",
        "    x = preprocess_input_Resnet50V2(x)\n",
        "    \n",
        "    #We do not want the base to be trainable, otherwise we would lose all the advantagres of using pre-trained model\n",
        "    conv_base_Resnet50V2  = ResNet50V2(weights='imagenet',include_top=False,input_shape=input_shape)\n",
        "    conv_base_Resnet50V2.trainable = False\n",
        "    conv_base_Resnet50V2.summary()\n",
        "\n",
        "    x = conv_base_Resnet50V2(x,training=False)\n",
        "    \n",
        "    #Rebuild top\n",
        "    #Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "    x = keras.layers.GlobalMaxPooling2D(name=\"top_GlobalMaxPooling2D\")(x)\n",
        "    x = layers.BatchNormalization(name=\"topBatchNorm\")(x)\n",
        "\n",
        "    dropout_rate = 0.5\n",
        "    x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)    \n",
        "\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "    outputs = layers.Dense(units, activation=activation, name=\"pred\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs, name=\"Resnet50V2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eblA97PaHyJp"
      },
      "source": [
        "#### EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHMQERqidjvg"
      },
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "#Make the EfficientNetB0 model\n",
        "def make_model_EfficientNetB0(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    preprocess_input_EfficientNetB0 = keras.applications.efficientnet.preprocess_input\n",
        "    x = preprocess_input_EfficientNetB0(x)\n",
        "    \n",
        "    #We do not want the base to be trainable, otherwise we would lose all the advantagres of using pre-trained model\n",
        "    conv_base_EfficientNetB0  = EfficientNetB0(weights='imagenet',include_top=False,input_tensor=x)\n",
        "    conv_base_EfficientNetB0.trainable = False\n",
        "    conv_base_EfficientNetB0.summary()\n",
        "\n",
        "    x = conv_base_EfficientNetB0(x, training=False)\n",
        "    \n",
        "    #Rebuild top\n",
        "    #Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "    x = keras.layers.GlobalMaxPooling2D(name=\"top_GlobalMaxPooling2D\")(x)\n",
        "    x = layers.BatchNormalization(name=\"topBatchNorm\")(x)\n",
        "\n",
        "    dropout_rate = 0.5\n",
        "    x = layers.Dropout(dropout_rate, name=\"top_dropout\")(x)    \n",
        "\n",
        "    activation = \"softmax\"\n",
        "    units = num_classes\n",
        "\n",
        "    outputs = layers.Dense(units, activation=activation, name=\"pred\")(x)\n",
        "    \n",
        "    return keras.Model(inputs, outputs, name=\"EfficientNetB0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UKbPAjtVWjP"
      },
      "source": [
        "## Part 3 - Compile and Train the CNN - FUNCTION\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMM89AWQfst1"
      },
      "source": [
        "### Compile the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CydyGbUaHyJt"
      },
      "source": [
        "#Define a function for the compilation of the models \n",
        "#The metrics used vary between a classification with two classes and one with more than two classes\n",
        "\n",
        "def compile_model(model_to_compile,model_arch_name):\n",
        "    if num_classes == 2:\n",
        "      loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "      METRICS = [\n",
        "                 'accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 tfa.metrics.F1Score(name='f1-score',average='macro',num_classes=num_classes,threshold=0.5)\n",
        "                 ]\n",
        "    else:\n",
        "      loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "      METRICS = [\n",
        "                 'accuracy',\n",
        "                 keras.metrics.Precision(name='precision'),\n",
        "                 keras.metrics.Recall(name='recall'),\n",
        "                 tfa.metrics.F1Score(name='f1-score',average='macro',num_classes=num_classes,threshold=0.5),\n",
        "                 tfa.metrics.F1Score(name='f1-score_perClass',num_classes=num_classes,threshold=0.5)\n",
        "                 ]\n",
        "    \n",
        "    #Set the intiial learning rate at 0.001\n",
        "    opt = Adam(lr=1e-3)\n",
        "    \n",
        "    model_to_compile.compile(optimizer=opt,\n",
        "              loss=loss_func,\n",
        "              metrics=METRICS)\n",
        "    \n",
        "    #Save the model plot if required to\n",
        "    if (save_shape_plot == True):\n",
        "      keras.utils.plot_model(model_to_compile,show_shapes=True,to_file=save_path+model_arch_name+\"_plot.png\")\n",
        "    return(model_to_compile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSvzlN2IVWja"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Validation set\n",
        "\n",
        "Callback: \n",
        "\n",
        "- EarlyStopping: Stop training the model if loss on validation set has not improved over 3 iterations\n",
        "- ModelCheckpoint: Save the best model based on the validation accuracy\n",
        "- WIP - TensorBoard: Generate the data for a tensorboard "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO_IjTqmHyJx"
      },
      "source": [
        "epochs = 3\n",
        "#Set to 30 because we do not want early stopping because of the Visual representations, but we still use early stopping in order to restore the best weights\n",
        "patience = epochs\n",
        "verbose = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PyphUmFHyJ2"
      },
      "source": [
        "#Define a function to build the callbacks\n",
        "def build_callback(model_name):\n",
        "    callbacks_list = [\n",
        "     keras.callbacks.EarlyStopping(\n",
        "         monitor=\"val_loss\",\n",
        "         patience=patience,\n",
        "         verbose=verbose,\n",
        "         mode=\"auto\",\n",
        "         restore_best_weights=True,\n",
        "     ),\n",
        "      keras.callbacks.TensorBoard(\n",
        "          log_dir=\"logs/fit/\"+model_name,\n",
        "          histogram_freq=1,\n",
        "          embeddings_freq=1,\n",
        "          )]\n",
        "    if save_model == True:\n",
        "      {\n",
        "        callbacks_list.append(\n",
        "         keras.callbacks.ModelCheckpoint(\n",
        "         filepath=save_path+\"\"+model_name+\".h5\",\n",
        "         monitor=\"val_loss\",\n",
        "         save_best_only=True,\n",
        "     ))\n",
        "      }\n",
        "\n",
        "    return(callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYaeXhc-j44D"
      },
      "source": [
        "#Define a function to train the model \n",
        "def train_model(model_to_train,callbacks):\n",
        "    model_to_train\n",
        "    history_model_to_train = model_to_train.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    return(model_to_train,history_model_to_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqJABTaCTnTi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnwul2CCVWj-"
      },
      "source": [
        "### Build chart to evaluate the model training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTZIYV0HxPdX"
      },
      "source": [
        "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "\n",
        "def plot_metrics(history, model_name):\n",
        "  metrics =  ['loss', 'accuracy']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend()\n",
        "    fig = plt.gcf()\n",
        "    if(save_training_plot == True):\n",
        "      fig.savefig(save_path+model_name+\"_training_plot.png\", dpi=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V79ulu5YRewP"
      },
      "source": [
        "### JSON export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRiyvMKHRiDj"
      },
      "source": [
        "def json_export(name, data):\n",
        "  df = pd.DataFrame.from_dict(data)\n",
        "  csv_path = save_path+module_name+\"_\"+model_version+\"_history_df_\"+name+\".csv\"\n",
        "  df.to_csv(csv_path, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oASjJtfoHyJ7"
      },
      "source": [
        "## Part 4 - Build the desired model\n",
        "Can only run one of the below, must restart the session in between the compilation of two model. The goal is to uniform the tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkbRt6M_gGJ9"
      },
      "source": [
        "### VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-QOpK0GHyKG"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model_VGG16 = make_model_VGG16(img_size+(3,),num_classes)\n",
        "model_VGG16 = compile_model(model_VGG16,\"VGG16\")\n",
        "model_VGG16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pGDJvXnHyKK"
      },
      "source": [
        "callbacks_VGG16 = build_callback(\"VGG16\")\n",
        "model_VGG16, history_model_VGG16 = train_model(model_VGG16, callbacks_VGG16)\n",
        "# Save it under the form of a json file\n",
        "if save_history == True:\n",
        "  json_export(\"VGG16\", history_model_VGG16.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlrV5cg1lGB1"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "plot_metrics(history_model_VGG16.history,\"VGG16\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyktVOr5gB6W"
      },
      "source": [
        "### Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UMBhLQFHyJ-"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model_Xception = make_model_Xception(img_size+(3,),num_classes)\n",
        "model_Xception = compile_model(model_Xception,\"Xception\")\n",
        "model_Xception.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmeORnEKHyKB"
      },
      "source": [
        "callbacks_Xception = build_callback(\"Xception\")\n",
        "model_Xception, history_model_Xception = train_model(model_Xception, callbacks_Xception)\n",
        "# Save it under the form of a json file\n",
        "if save_history == True:\n",
        "  json_export(\"Xception\", history_model_Xception.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NKXS8uVaYGK"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "plot_metrics(history_model_Xception.history,\"Xception\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh4hdYwGdj0z"
      },
      "source": [
        "### Resnet50V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNW2BnsBdj01"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model_Resnet50V2 = make_model_Resnet50V2(img_size+(3,),num_classes)\n",
        "model_Resnet50V2 = compile_model(model_Resnet50V2,\"Resnet50V2\")\n",
        "model_Resnet50V2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svi_DI7Tdj1g"
      },
      "source": [
        "callbacks_Resnet50V2 = build_callback(\"Resnet50V2\")\n",
        "model_Resnet50V2, history_model_Resnet50V2 = train_model(model_Resnet50V2, callbacks_Resnet50V2)\n",
        "# Save it under the form of a json file\n",
        "if save_history == True:\n",
        "  json_export(\"Resnet50V2\", history_model_Resnet50V2.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f42QpPjtax8o"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "plot_metrics(history_model_Resnet50V2.history,\"Resnet50V2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ3xskFNdj2A"
      },
      "source": [
        "### EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klrO_Hjwdj2D"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model_EfficientNetB0 = make_model_EfficientNetB0(img_size+(3,),num_classes)\n",
        "model_EfficientNetB0 = compile_model(model_EfficientNetB0,\"EfficientNetB0\")\n",
        "model_EfficientNetB0.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4upOPftKdj2b"
      },
      "source": [
        "callbacks_EfficientNetB0 = build_callback(\"EfficientNetB0\")\n",
        "model_EfficientNetB0, history_model_EfficientNetB0 = train_model(model_EfficientNetB0, callbacks_EfficientNetB0)\n",
        "# Save it under the form of a json file\n",
        "if save_history == True:\n",
        "  json_export(\"EfficientNetB0\", history_model_EfficientNetB0.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhgcPVaZa4zn"
      },
      "source": [
        "mpl.rcParams['figure.figsize'] = (12, 10)\n",
        "plot_metrics(history_model_EfficientNetB0.history,\"EfficientNetB0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqXKqYJCQEyi"
      },
      "source": [
        "# Tensorboard\n",
        "\n",
        "Below is the code to upload the training logs to Tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cc8lFp3GKI6"
      },
      "source": [
        "#Update to Tensorboard\n",
        "!tensorboard dev upload --logdir ./logs \\\n",
        "  --name \"Module 1 - Model Selection - vF\" \\\n",
        "  --description \"GlobalMax Pooling, Batch Normalization, Dropout = 0.5\" \\\n",
        "  --one_shot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HQoqYRufnG1"
      },
      "source": [
        "## Access Tensorboard and build chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M00hkqtafu1V"
      },
      "source": [
        "experiment_id = \"ID RETURNED ABOVE\"\n",
        "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
        "df = experiment.get_scalars()\n",
        "print(df[\"run\"].unique())\n",
        "print(df[\"tag\"].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITaIBkqAgbeL"
      },
      "source": [
        "dfw = experiment.get_scalars(pivot=True) \r\n",
        "dfw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idD40JM8ghdM"
      },
      "source": [
        "csv_path = save_path+module_name+\"_\"+model_version+\"_experiment.csv\"\n",
        "dfw.to_csv(csv_path, index=False)\n",
        "dfw_roundtrip = pd.read_csv(csv_path)\n",
        "pd.testing.assert_frame_equal(dfw_roundtrip, dfw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDvRj250prxu"
      },
      "source": [
        "# Filter the DataFrame to only validation data, which is what the subsequent\r\n",
        "# analyses and visualization will be focused on.\r\n",
        "dfw_validation = dfw[dfw.run.str.endswith(\"/validation\")]\r\n",
        "# Get the optimizer value for each row of the validation DataFrame.\r\n",
        "optimizer_validation = dfw_validation.run.apply(lambda run: run.split(\",\")[0])\r\n",
        "\r\n",
        "plt.figure(figsize=(16, 6))\r\n",
        "plt.subplot(1, 2, 1)\r\n",
        "sns.lineplot(data=dfw_validation, x=\"step\", y=\"epoch_f1-score\", \r\n",
        "             hue=optimizer_validation).set_title(\"f1-score\")\r\n",
        "plt.subplot(1, 2, 2)\r\n",
        "sns.lineplot(data=dfw_validation, x=\"step\", y=\"epoch_loss\",\r\n",
        "             hue=optimizer_validation).set_title(\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnXlm7nQW79L"
      },
      "source": [
        "dfw_validation.groupby('run')['epoch_f1-score'].nlargest(1,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuKS1s_ad54u"
      },
      "source": [
        "### EfficientNet-B0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndIxSFH4d69y"
      },
      "source": [
        "dfw_EfficientNetB0 = dfw[dfw.run.str.startswith(\"fit/EfficientNetB0\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsmTknUBd6m_"
      },
      "source": [
        "# Get the optimizer value for each row of the validation DataFrame.\r\n",
        "optimizer_validation = dfw_EfficientNetB0.run.apply(lambda run: run.split(\",\")[0])\r\n",
        "\r\n",
        "plt.figure(figsize=(16, 6))\r\n",
        "plt.subplot(1, 3, 1)\r\n",
        "sns.lineplot(data=dfw_EfficientNetB0, x=\"step\", y=\"epoch_f1-score\", \r\n",
        "             hue=optimizer_validation).set_title(\"f1-score\")\r\n",
        "plt.subplot(1, 3, 2)\r\n",
        "sns.lineplot(data=dfw_EfficientNetB0, x=\"step\", y=\"epoch_accuracy\",\r\n",
        "             hue=optimizer_validation).set_title(\"accuracy\")\r\n",
        "plt.subplot(1, 3, 3)\r\n",
        "sns.lineplot(data=dfw_EfficientNetB0, x=\"step\", y=\"epoch_loss\",\r\n",
        "             hue=optimizer_validation).set_title(\"loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAc5rvOVWkY"
      },
      "source": [
        "# Load and evaluate models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkm02p53geTD"
      },
      "source": [
        "## Part 1 - Load the model and evaluate its accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnJAcAL-gpe7"
      },
      "source": [
        "#model = model_VGG16\n",
        "#model_name = \"VGG16\"\n",
        "#model = model_Xception\n",
        "#model_name = \"Xception\"\n",
        "#model = model_Resnet50V2\n",
        "#model_name = \"Resnet50V2\"\n",
        "model = model_EfficientNetB0\n",
        "model_name = \"EfficientNetB0\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ney64gZDJjKA"
      },
      "source": [
        "def model_accuracy():\n",
        "  loss, acc, prec, reca, f1 = model.evaluate(test_ds)\n",
        "  print('Restored model '+model_name+', accuracy: {:5.2f}%'.format(100*acc))\n",
        "  print(model.predict(test_ds).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoXVJ3OAVWka"
      },
      "source": [
        "model_accuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7vuuMOEVWk7"
      },
      "source": [
        "## Part 2 - Proceed to multiple predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PPkvgB-Kjl4"
      },
      "source": [
        "def model_predict():\n",
        "  #Retrieve a batch of images from the test set\n",
        "  image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
        "  predictions = model.predict_on_batch(image_batch)\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "    x = class_names[np.argmax(label_batch[i])]\n",
        "    y = class_names[np.argmax(predictions[i])]\n",
        "    plt.title(\"Actual:\"+ x +\"\\nPredicted:\"+ y +\"\")\n",
        "    plt.axis(\"off\")\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAgw-htgVWk8"
      },
      "source": [
        "#Retrieve a batch of images from the test set\n",
        "predictions = model_predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkvdPzRyM_yP"
      },
      "source": [
        "#Check\n",
        "np.sum(predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYHAov_HdL27"
      },
      "source": [
        "## Part 3 - Single Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o93SXb9hxKo"
      },
      "source": [
        "img_path = \"IMG_PATH\"\n",
        "\n",
        "img = keras.preprocessing.image.load_img(\n",
        "      img_path, target_size=img_size\n",
        "  )\n",
        "\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "print(f\"The algorithm says this image is:\\n {prediction[0,0]:.2%} {class_names[0]}\\n and {prediction[0,1]:.2%} {class_names[1]}\\n\")\n",
        "img\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}